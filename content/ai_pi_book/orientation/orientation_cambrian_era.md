# Working in AI's Pre-Textbook, Cambrian Era

```{note}
**This page is incomplete and under active development.** We welcome your suggestions and feedback! Please feel free to contribute or reach out with ideas for improvement.
```

Artificial intelligence is often treated as a mature scientific discipline, comparable to physics or chemistry. This is a mistake. AI today is extraordinarily powerful, but scientifically young.

Biologists are used to fields where discovery outpaces textbooks. Yet even by those standards, modern AI is unusually early in its development. To understand where we truly are, three historical analogies are helpful.

**1. The Cambrian explosion.**  
The Cambrian period was marked by a rapid diversification of biological forms. Most body plans went extinct; only a few stabilized and became the foundation of modern life.

AI today feels like this moment. Architectures, paradigms, and representations are proliferating rapidly—transformers, diffusion models, foundation models, multimodal systems, agents. Many will fade. A small number will define the field for decades. We do not yet know which ones.

**2. Steam engines before thermodynamics.**  
During the first industrial revolution, steam engines transformed society long before thermodynamics existed. Engineers knew how to build machines that worked, but not why certain designs were efficient or what their fundamental limits were. Theory followed practice.

Modern AI is in a similar state. Deep learning systems work—often remarkably well—but theory lags far behind empirical success. Architectures and training strategies are adopted because they perform well, not because they are derived from first principles.

**3. Alchemy before chemistry.**  
Modern AI also resembles alchemy before chemistry: powerful and outcome-driven, rich in empirical recipes that work in practice, yet still lacking clean concepts, causal explanations, and unifying laws. The results are real, but the language is often loose, metaphorical, and ahead of understanding.

This is why AI should not be approached as a settled discipline. There is no canonical textbook. Much of the field’s knowledge lives in code, benchmarks, and informal consensus. Concepts are fluid, and terminology often runs ahead of understanding.

Breakthroughs after 2017—especially large-scale self-supervised learning—unlocked capabilities that existing theory did not predict. AlphaFold is a clear example: its architectural components are justified primarily by empirical success, while deeper explanations remain active research questions. The same is true for protein language models and what they truly learn.

This gap between capability and understanding is not a flaw. It is a defining feature of a field in its formative phase—and a rare moment of opportunity.

---

## Practical Challenges for Newcomers, Especially Biologists

This formative state creates specific friction points for researchers entering the field:

- **Terminology without formal definitions.** Many core terms—AI, machine learning, deep learning, neural networks—are defined only through community convention rather than standardized meaning.
- **Difficult entry by reading.** Concepts like transformers vs. diffusion models or LLMs vs. other architectures cannot be understood reliably through passive reading alone, because the literature itself is evolving and inconsistent.
- **No clear answers to seemingly basic questions.** Examples include: Why use CNNs instead of LSTMs in certain domains? Are transformers always better? When does a simple model outperform a sophisticated one? In many cases, the field has no settled consensus.

---

> ## Core Takeaways
> **• Do not treat AI as a mature field.**  
> AI is powerful, but its scientific foundations are still forming.
>
> **• We are in a pre-textbook era.**  
> Practice, recipes, and intuition currently dominate over theory.
>
> **• AI is in a Cambrian phase.**  
> Rapid diversification is expected; most ideas will not survive.
>
> **• This is a chance to write history.**  
> Today’s practitioners—especially in biology—help decide which abstractions become the future fundamentals.
>
> **• You are not just learning AI.**  
> You are participating in the formation of the field itself.
